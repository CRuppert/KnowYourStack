{"Data":{"GitHub":{"Issues":[{"Id":"615403389","IsPullRequest":false,"CreatedAt":"2020-05-10T14:29:31","Actor":"adriansd27","Number":"5113","RawContent":null,"Title":"evaluating model in asp.net core","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: ASP.NET Core 3.1\r\n\r\n### Issue\r\n\r\nI'm running ASP.NET Core 3.1. Training the model works fine. PredictionEnginePool predicts fine. However if I try to get the metrics of the trained model I'm getting the below exception. Is it that ASP.NET Core doesn't support System.Drawing.Bitmap? If so, is there any alternative option to evaluate a model in ASP.NET Core?\r\n\r\n### Source code / logs\r\n\r\n     var trainingData = _mlContext.Data.LoadFromEnumerable(imageDataTags);\r\n     var model = pipeline.Fit(trainingData);\r\n     var testingData = _mlContext.Data.LoadFromEnumerable(testImageDataTags);\r\n     var predictions = model.Transform(testingData);\r\n     var metrics = _mlContext.MulticlassClassification.Evaluate(predictions,\"LabelKey\");\r\n\r\n```System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data\r\n ---> System.ArgumentException: Parameter is not valid.\r\n   at System.Drawing.Bitmap..ctor(String filename, Boolean useIcm)\r\n   at System.Drawing.Bitmap..ctor(String filename)\r\n   at Microsoft.ML.Data.ImageLoadingTransformer.Mapper.<>c__DisplayClass4_0.<MakeGetterImageDataViewType>b__0(Bitmap& dst)\r\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)\r\n   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.TensorValueGetterVec`1.GetTensor()\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, ITensorValueGetter[] srcTensorGetters, String[] activeOutputColNames, OutputCache outputCache)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.SchemaBindablePredictorWrapperBase.<>c__DisplayClass18_0`2.<GetValueGetter>b__0(TDst& dst)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass5_1.<ConsolidateCore>b__2()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.EvaluatorBase`1.ProcessData(IDataView data, RoleMappedSchema schema, Func`2 activeColsIndices, TAgg aggregator, AggregatorDictionaryBase[] dictionaries)\r\n   at Microsoft.ML.Data.EvaluatorBase`1.Microsoft.ML.Data.IEvaluator.Evaluate(RoleMappedData data)\r\n   at Microsoft.ML.Data.MulticlassClassificationEvaluator.Evaluate(IDataView data, String label, String score, String predictedLabel)\r\n   at Microsoft.ML.MulticlassClassificationCatalog.Evaluate(IDataView data, String labelColumnName, String scoreColumnName, String predictedLabelColumnName, Int32 topKPredictionCount)\r\n   at PDCSBE.Services.Implementation.PredictionService.TrainModel() in D:\\...\\Services\\Implementation\\PredictionService.cs:line 91\r\n   at PDCSBE.Api.Controllers.PredictController.TrainModel(ModelTrainerDataInputDto input) in D:\\...\\Controllers\\PredictController.cs:line 26\r\n   at lambda_method(Closure , Object , Object[] )\r\n   at Microsoft.Extensions.Internal.ObjectMethodExecutor.Execute(Object target, Object[] parameters)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Logged|12_1(ControllerActionInvoker invoker)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeFilterPipelineAsync>g__Awaited|19_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Logged|17_1(ResourceInvoker invoker)\r\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\r\n   at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)\r\n   at Microsoft.AspNetCore.Routing.EndpointRoutingMiddleware.<Invoke>g__AwaitMatcher|8_0(EndpointRoutingMiddleware middleware, HttpContext httpContext, Task`1 matcherTask)\r\n   at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)\r\n\r\nHEADERS\r\n=======\r\nAccept: */*\r\nAccept-Encoding: gzip, deflate, br\r\nCache-Control: no-cache\r\nConnection: keep-alive\r\nContent-Length: 214\r\nContent-Type: application/json\r\nHost: localhost:44370\r\nUser-Agent: PostmanRuntime/7.24.1\r\nPostman-Token: ced1eca6-9e0b-4292-9887-f46a6d1c57d5\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/5113","RelatedDescription":"Open issue \"evaluating model in asp.net core\" (#5113)"},{"Id":"615394321","IsPullRequest":false,"CreatedAt":"2020-05-10T13:41:21","Actor":"ddobric","Number":"5112","RawContent":null,"Title":"Running ImageClassification in parallel","State":"open","Body":"Using ImageClassification (ImageClassificationTrainer) on the machine as a job.\r\nThe job is implemented as a Azure Function, which is triggered by message in the storage queue. Every time the job receive a message the training process is calculated. The training runs for different data sets. That means, the function can observe multiple requests \r\n\r\nUnfortunately, when two training are running simultaneously on the same machine, we get following error:\r\n```\r\n\r\n2020-05-10T13:27:27  PID[11748] Information  ---> System.IO.IOException: Could not open file 'C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\LocalAppData\\cache\\bottleneck_train_cache.cac'. Error is: The process cannot access the file 'C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\LocalAppData\\cache\\bottleneck_train_cache.cac' because it is being used by another process.\r\n2020-05-10T13:27:27  PID[11748] Information  ---> System.IO.IOException: The process cannot access the file '***\\LocalAppData\\cache\\bottleneck_train_cache.cac' because it is being used by another process.\r\n2020-05-10T13:27:27  PID[11748] Information    at System.IO.FileStream.ValidateFileHandle(SafeFileHandle fileHandle)\r\n2020-05-10T13:27:27  PID[11748] Information    at System.IO.FileStream.CreateFileOpenHandle(FileMode mode, FileShare share, FileOptions options)\r\n2020-05-10T13:27:27  PID[11748] Information    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options)\r\n2020-05-10T13:27:27  PID[11748] Information    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share)\r\n2020-05-10T13:27:27  PID[11748] Information    at Microsoft.ML.Internal.Utilities.StreamUtils.OpenInStream(String fileName)\r\n2020-05-10T13:27:27  PID[11748] Information    at Microsoft.ML.Data.MultiFileSource.Open(Int32 index)\r\n2020-05-10T13:27:27  PID[11748] Information    --- End of inner exception stack trace ---\r\n```\r\n\r\nBy following the error shown above, it looks as trainer uses internal a local file(s), which should not be touched by multiple threads.\r\nI guess, this can be solved by providing a different 'WorkspacePath' for every request? In any case, such internal details, should be transparent for developers. Moreover, ML algorithms, at least in the .NET ecosystem should not internal create any kind of singleton inside of process and also machine.\r\nThis is very untypical for .NET. \r\n\r\nIn my opinion this is a not best design and it should should be fixed. ","Url":"https://github.com/dotnet/machinelearning/issues/5112","RelatedDescription":"Open issue \"Running ImageClassification in parallel\" (#5112)"},{"Id":"615265479","IsPullRequest":false,"CreatedAt":"2020-05-09T21:42:00","Actor":"ddobric","Number":"5111","RawContent":null,"Title":"Issue with \"TrainingSetSize.txt\"","State":"open","Body":"Running the ML.NET image classification inside of WebJob (windows platform/.NET Core 3.1)\r\nAll works fine when executed locally. Unfortunately, when running as job it fails with the following error: \r\n\r\n> 2020-05-09T19:30:04  PID[9552] Information       The building model process has failed.\r\n> 2020-05-09T19:30:04  PID[9552] Information System.IO.FileNotFoundException: Could not find file 'C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\cache\\TrainingSetSize.txt'.\r\n> 2020-05-09T19:30:04  PID[9552] Information File name: 'C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\cache\\TrainingSetSize.txt'\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.FileStream.ValidateFileHandle(SafeFileHandle fileHandle)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.FileStream.CreateFileOpenHandle(FileMode mode, FileShare share, FileOptions options)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.StreamReader.ValidateArgsAndOpenPath(String path, Encoding encoding, Int32 bufferSize)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.StreamReader..ctor(String path)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at System.IO.File.OpenText(String path)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Vision.ImageClassificationTrainer.GetNumSamples(String path)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Vision.ImageClassificationTrainer.TrainAndEvaluateClassificationLayer(String trainBottleneckFilePath, Options options, String validationSetBottleneckFilePath, Int32 trainingsetSize)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Vision.ImageClassificationTrainer.TrainModelCore(TrainContext trainContext)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Trainers.TrainerEstimatorBase`2.Fit(IDataView input)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.TrainCatalogBase.CrossValidateTrain(IDataView data, IEstimator`1 estimator, Int32 numFolds, String samplingKeyColumn, Nullable`1 seed)\r\n> 2020-05-09T19:30:04  PID[9552] Information    at Microsoft.ML.MulticlassClassificationCatalog.CrossValidate(IDataView data, IEstimator`1 estimator, Int32 numberOfFolds, String labelColumnName, String samplingKeyColumnName, Nullable`1 seed)\r\n\r\nCreating of the text file seems not to be correctly implemented. If the path is not set to the permitted location, the required text file will not be created. In that case another error message should be created. \r\nFor example, following path is in WebJob (hosted in IIS) not allowed:\r\n\r\n`C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob`\r\n\r\nIt corresponds to %AppData% of the local machine. It is the working folder of IIS in context of an Azure Job. By changing the path to following one, all will work fine:\r\n\r\n`C:\\DWASFiles\\Sites\\#1prodidentweb-training-webjob\\Local`\r\n \r\nIn the code, this can be achieved by following:\r\n~~~\r\nWorkspacePath = Environment.GetFolderPath(Environment.SpecialFolder.LocalApplicationData),\r\n~~~\r\n\r\n### Recap\r\nTrainer creates internally many files. One of them is *TrainingSetSize.txt*. If the *options.WorkspacePath* is set to location on which the process has no write permission, the correct exception should be thrown. \r\n\r\nThis might also be a security issue is one chose path like \"WorkspacePath = \"..\\..\\xy\". That would lead the job process to touch the path, which possibly belongs to the job owned by some other customer. At the moment of writing of this, I didn't see security issue here, but who know what might happen in the future.","Url":"https://github.com/dotnet/machinelearning/issues/5111","RelatedDescription":"Open issue \"Issue with \"TrainingSetSize.txt\"\" (#5111)"},{"Id":"613705654","IsPullRequest":true,"CreatedAt":"2020-05-09T07:46:45","Actor":"frank-dong-ms","Number":"5102","RawContent":null,"Title":"address TF test download fail, use resource manager with retry download","State":"closed","Body":"address below exception on OSX:\r\n\r\nX Microsoft.ML.Scenarios.TensorFlowScenariosTests.TensorFlowTransforCifarEndToEndTest2 [1ms]\r\n  Error Message:\r\n   System.Net.WebException : Device not configured Device not configured\r\n---- System.Net.Http.HttpRequestException : Device not configured\r\n-------- System.Net.Sockets.SocketException : Device not configured\r\n  Stack Trace:\r\n     at System.Net.HttpWebRequest.GetResponse()\r\n   at System.Net.WebClient.GetWebResponse(WebRequest request)\r\n   at System.Net.WebClient.DownloadBits(WebRequest request, Stream writeStream)\r\n   at System.Net.WebClient.DownloadFile(Uri address, String fileName)\r\n   at System.Net.WebClient.DownloadFile(String address, String fileName)\r\n   at Microsoft.ML.Scenarios.TensorFlowScenariosTests.Download(String url, String destDir, String destFileName) \r\n\r\n\r\naccording to below issue and suggestion (The OSX resolve seems more fragile than other implementation), we retry download:\r\nhttps://github.com/dotnet/runtime/issues/30678 ","Url":"https://github.com/dotnet/machinelearning/pull/5102","RelatedDescription":"Closed or merged PR \"address TF test download fail, use resource manager with retry download\" (#5102)"},{"Id":"614426575","IsPullRequest":true,"CreatedAt":"2020-05-09T06:39:10","Actor":"frank-dong-ms","Number":"5108","RawContent":null,"Title":"test move back to host see if still hangs","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5108","RelatedDescription":"Closed or merged PR \"test move back to host see if still hangs\" (#5108)"},{"Id":"614980242","IsPullRequest":true,"CreatedAt":"2020-05-09T05:47:37","Actor":"mstfbl","Number":"5110","RawContent":null,"Title":"Disabled BinaryClassifierSymSgdTest for test stability","State":"closed","Body":"\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5110","RelatedDescription":"Closed or merged PR \"Disabled BinaryClassifierSymSgdTest for test stability\" (#5110)"},{"Id":"613586028","IsPullRequest":true,"CreatedAt":"2020-05-09T04:54:17","Actor":"Lynx1820","Number":"5098","RawContent":null,"Title":"Adding OneHotHashEncoding Test","State":"closed","Body":"Test that uses OneHotEncoding and MurmurHash transformers\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5098","RelatedDescription":"Closed or merged PR \"Adding OneHotHashEncoding Test\" (#5098)"},{"Id":"612858082","IsPullRequest":false,"CreatedAt":"2020-05-08T23:07:07","Actor":"mstfbl","Number":"5093","RawContent":null,"Title":"Ubuntu ML .NET Docker Image has no configured locales","State":"closed","Body":"The Ubuntu ML .NET Docker image does not have configured locals, which is resulting in the following error statement:\r\n\r\n>    System.InvalidOperationException : Error initializing model :Microsoft.ML.OnnxRuntime.OnnxRuntimeException: [ErrorCode:RuntimeException] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cpu/nn/string_normalizer.cc:87 onnxruntime::string_normalizer::Locale::Locale(const string&) Failed to construct locale with name:en_US.UTF-8:locale::facet::_S_create_c_locale name not valid:Please, install necessary language-pack-XX and configure locales\r\n\r\nThis error is the reason why `TextNormalizingOnnxConversionTest()` is currently disabled on Linux at line 462:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/c83ea54a0874fbeac0d16cb5f31e3cd97f8d97ed/test/Microsoft.ML.Tests/OnnxConversionTest.cs#L440-L473\r\n\r\nThe ONNX Runtime team encountered a similar issue with their docker images and fixed it with [onnxruntime PR#19](https://github.com/onnx/backend-scoreboard/pull/19), where `locales` was installed with `apt-get` and the `en_US.UTF-8` locale was configured.\r\n\r\n**TODO**: Edit the Dockerfile (which is not in this repo) for our Ubuntu builds and add the following:\r\n```\r\nRUN apt-get update && apt-get install -y locales\r\nRUN locale-gen en_US.UTF-8 && update-locale LANG=en_US.UTF-8\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/5093","RelatedDescription":"Closed issue \"Ubuntu ML .NET Docker Image has no configured locales\" (#5093)"},{"Id":"614974792","IsPullRequest":false,"CreatedAt":"2020-05-08T20:39:16","Actor":"ibebbs","Number":"5109","RawContent":null,"Title":"Training / Predicting from in-memory Bitmap","State":"open","Body":"Hi,\r\n\r\nJust started playing with Microsoft.ML and am pretty impressed. I followed [this tutorial](https://devblogs.microsoft.com/dotnet/train-image-classification-model-azure-mlnet-model-builder/) to build an image classifier model that works reasonably well (limited training data). I now want to put this model to use but have hit an issue:\r\n\r\nThe images I want to classify will be in-memory (as a Bitmap) but the trained model seems to need the images on disk. Obviously I could save the image to a temporary file but this seems wasteful when the model will need to read it back in again. From what I can see in the source code, the \"LoadRawImageBytes\" transform from the [Model Builder generated] pipeline shown below doesn't have any kind of overload for loading in-memory data:\r\n\r\n```c#\r\nvar pipeline = context.Transforms.Conversion.MapValueToKey(\"Label\", \"Label\")\r\n    .Append(context.Transforms.LoadRawImageBytes(\"ImageSource_featurized\", null, \"Image\"))\r\n    .Append(context.Transforms.CopyColumns(\"Features\", \"ImageSource_featurized\"));\r\n```\r\n\r\nAfter a lot of searching I found [this issue](https://github.com/dotnet/machinelearning/issues/4944) in which @huy-lv asks how to do pretty much exactly what I want to do. @Lynx1820 replied pointing to [this sample](https://github.com/dotnet/machinelearning-samples/tree/e43e429cce06f246a38053e01f1a8e9392f2d36f/samples/csharp/end-to-end-apps/DeepLearning_ImageClassification_TensorFlow) which I have endeavoured to follow.\r\n\r\nI now have the following pipeline:\r\n\r\n```c#\r\nvar pipeline = context.Transforms.Conversion.MapValueToKey(\"Label\", \"Label\")\r\n    .Append(context.Transforms.ResizeImages(outputColumnName: \"ScaledImage\", imageWidth: 227, imageHeight: 227, inputColumnName: \"Image\"))\r\n    .Append(context.Transforms.ExtractPixels(outputColumnName: \"ImageSource_featurized\", inputColumnName: \"ScaledImage\", outputAsFloatArray: false))\r\n    .Append(context.Transforms.CopyColumns(\"Features\", \"ImageSource_featurized\"));\r\n\r\nvar trainer = context.MulticlassClassification.Trainers.ImageClassification(new ImageClassificationTrainer.Options() { LabelColumnName = \"Label\", FeatureColumnName = \"Features\" })\r\n    .Append(context.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\", \"PredictedLabel\"));\r\n\r\nvar trainingPipeline = pipeline.Append(trainer);\r\n```\r\n\r\nBut when I try to train the model (with `trainingPipeline.Fit(trainingData)`) I receive the error:\r\n\r\n`Schema mismatch for feature column 'Features': expected VarVector<Byte>, got Vector<Byte> '`\r\n\r\nCould you provide an example of how to use `Transforms.ExtractPixels` with `MulticlassClassification.Trainers.ImageClassification` or suggestions on how to train/predict from an in-memory `Bitmap` source?\r\n\r\nThanks!","Url":"https://github.com/dotnet/machinelearning/issues/5109","RelatedDescription":"Open issue \"Training / Predicting from in-memory Bitmap\" (#5109)"},{"Id":"612246446","IsPullRequest":true,"CreatedAt":"2020-05-08T20:06:34","Actor":"Lynx1820","Number":"5090","RawContent":null,"Title":"Adding vector tests for KeyToValue and ValueToKey","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/5090","RelatedDescription":"Closed or merged PR \"Adding vector tests for KeyToValue and ValueToKey\" (#5090)"},{"Id":"611758370","IsPullRequest":false,"CreatedAt":"2020-05-08T16:52:38","Actor":"adriansd27","Number":"5088","RawContent":null,"Title":"Update ML.NET trained Model in ASP.NET Core without restarting the app","State":"closed","Body":"### System information\r\nWindows 10\r\n- **OS version/distro**: Education\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 3.1\r\n\r\n### Issue\r\nUnable to update a ML.NET trained model in ASP.NET Core without restarting the web app\r\n- **What did you do?**\r\n\r\nLike the title says, I'm trying to retrain an existing ML.NET model in an ASP.NET Core web app. The setup: I have an existing model.zip file on the local disk. In Startup.cs I'm injecting the prediction engine pool service\r\n\r\n`services.AddPredictionEnginePool<ImageData, ImagePrediction>().FromFile(\r\n        \"ImageClassificationModel\", _modelPath, true);`\r\n\r\nby loading the existing model from the disk. The _modelPath variable indicates the path to the zip file, and the true parameter indicates that the Prediction Engine Pool should watch the model for changes. According to https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/serve-model-web-api-ml-net,\r\n\r\n> The PredictionEnginePool service provides a mechanism to reload an updated model without taking your application down.\r\n\r\nI've also created a service that takes the path to some image folders and trains a new model, then saves it to the same location _modelPath indicates. That service is exposed through an API Endpoint.\r\n\r\n- **What happened?**\r\n\r\nThe problem: When accessing the train endpoint, the app works fine. It retrains the model and saves it to the indicated path. I can do this several times. However, if I use the model to predict an image's label, I'm no longer able to retrain the model. If I try to call the train endpoint again, I'm getting an error that says the model file is already in use.\r\n\r\n> System.IO.IOException: 'The process cannot access the file '\\MLModel\\model.zip' because it is being used by another process.'\r\n\r\nThe only way to update the model so far would be to completely restart the web app and call the train endpoint first thing.\r\n\r\n- **What did you expect?**\r\n\r\nThe expected result would be able to retrain the model without restarting the web app.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5088","RelatedDescription":"Closed issue \"Update ML.NET trained Model in ASP.NET Core without restarting the app\" (#5088)"},{"Id":"614424101","IsPullRequest":true,"CreatedAt":"2020-05-08T00:38:22","Actor":"frank-dong-ms","Number":"5107","RawContent":null,"Title":"try use other agent pool","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5107","RelatedDescription":"Closed or merged PR \"try use other agent pool\" (#5107)"},{"Id":"614309686","IsPullRequest":true,"CreatedAt":"2020-05-07T20:02:57","Actor":"michaelgsharp","Number":"5106","RawContent":null,"Title":"added in standard conversions from types to ReadOnlyMemory<char>","State":"open","Body":"Currently in the standard transformations we don't support converting types to a string representation. Since all C# types support `ToString()` functionality, this PR adds in standard transformations to type `ReadOnlyMemory<char>` into the `TypeConvertingTransformer`.","Url":"https://github.com/dotnet/machinelearning/pull/5106","RelatedDescription":"Open PR \"added in standard conversions from types to ReadOnlyMemory<char>\" (#5106)"},{"Id":"613630404","IsPullRequest":true,"CreatedAt":"2020-05-07T17:02:29","Actor":"frank-dong-ms","Number":"5100","RawContent":null,"Title":"pipeline configuration change","State":"closed","Body":"1. make code coverage timeout to 90 minutes due to frequent timeout at code coverage pipeline\r\n2. move nightly build pipeline to netcore app agent pool as we see disk out of space error\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5100","RelatedDescription":"Closed or merged PR \"pipeline configuration change\" (#5100)"},{"Id":"614199695","IsPullRequest":false,"CreatedAt":"2020-05-07T16:47:22","Actor":"Neoplayer","Number":"5105","RawContent":null,"Title":"Regression with image","State":"closed","Body":"How to concatenate image with some Single values? I was trying to convert image to `ExtractPixels` and `LoadRawImageBytes` but I can't find any way to concatenate this with single values. ","Url":"https://github.com/dotnet/machinelearning/issues/5105","RelatedDescription":"Closed issue \"Regression with image\" (#5105)"},{"Id":"614171721","IsPullRequest":true,"CreatedAt":"2020-05-07T16:02:46","Actor":"wangyems","Number":"5104","RawContent":null,"Title":"Support more types for HashEstimator","State":"open","Body":"-Verified compatibility between ORT(https://github.com/microsoft/onnxruntime/pull/3827) and ML.NET\r\n-Some changes made in a couple of 64-bit hash function because the existed implementation is not exactly the same as MurmurHash3_x86_32\r\n-No merging until ort PR goes in and bump ort version.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5104","RelatedDescription":"Open PR \"Support more types for HashEstimator\" (#5104)"},{"Id":"613037668","IsPullRequest":true,"CreatedAt":"2020-05-07T06:19:06","Actor":"suxi-ms","Number":"5095","RawContent":null,"Title":"Suxi/no transformer","State":"closed","Body":"This is a tempory PR to review root cause analysis's implemention by using no transformer. Original one is [here](https://github.com/dotnet/machinelearning/pull/4925)\r\n\r\n\r\n- [ ] Fixes #4960 .\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5095","RelatedDescription":"Closed or merged PR \"Suxi/no transformer\" (#5095)"},{"Id":"613776008","IsPullRequest":true,"CreatedAt":"2020-05-07T05:08:31","Actor":"frank-dong-ms","Number":"5103","RawContent":null,"Title":"troubleshoot hanging","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5103","RelatedDescription":"Open PR \"troubleshoot hanging\" (#5103)"},{"Id":"613577783","IsPullRequest":true,"CreatedAt":"2020-05-07T00:12:44","Actor":"harishsk","Number":"5097","RawContent":null,"Title":"Changed Dictionary to ConcurrentDictionary","State":"closed","Body":"We are seeing new test failure sporadically with the following call stack:\r\n\r\n```\r\n[xUnit.net 00:00:05.18]     Microsoft.ML.Functional.Tests.Debugging.ViewTrainingOutput [FAIL]\r\n\r\n  X Microsoft.ML.Functional.Tests.Debugging.ViewTrainingOutput [16ms]\r\n  Error Message:\r\n   System.InvalidOperationException : Operations that change non-concurrent collections must have exclusive access. A concurrent update was performed on this collection and corrupted its state. The collection's state is no longer correct.\r\n  Stack Trace:\r\n     at System.Collections.Generic.Dictionary`2.FindEntry(TKey key)\r\n   at System.Collections.Generic.Dictionary`2.ContainsKey(TKey key)\r\n   at Microsoft.ML.Functional.Tests.Debugging.LogWatcher.ObserveEvent(Object sender, LoggingEventArgs e) in /Users/runner/runners/2.166.3/work/1/s/test/Microsoft.ML.Functional.Tests/Debugging.cs:line 204\r\n   at Microsoft.ML.MLContext.ProcessMessage(IMessageSource source, ChannelMessage message) in /Users/runner/runners/2.166.3/work/1/s/src/Microsoft.ML.Data/MLContext.cs:line 135\r\n   at Microsoft.ML.Runtime.HostEnvironmentBase`1.Dispatcher`1.DispatchCore(IMessageSource sender, TMessage message) in /Users/runner/runners/2.166.3/work/1/s/src/Microsoft.ML.Core/Environment/HostEnvironmentBase.cs:line 314\r\n```\r\n\r\nSince the dictionary is being modified by multiple threads, I am changing this to a ConcurrentDictionary.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5097","RelatedDescription":"Closed or merged PR \"Changed Dictionary to ConcurrentDictionary\" (#5097)"},{"Id":"613641823","IsPullRequest":false,"CreatedAt":"2020-05-06T22:04:14","Actor":"kik3r","Number":"5101","RawContent":null,"Title":"Negative scores evalauate for LightGBMMulti model","State":"open","Body":"I have a multi class classification model trained to classify to 3 values (-1,0,1) looking at 26 feature columns which are RGB color values as float.\r\nwhen predicting, score values returned are sometimes negative. From my basic understanding, the score values are confidence on each class and they should add up to 1 and each value should be between 0 and 1.\r\n\r\nModel was created using AutoML.\r\nMulticlassExperimentSettings settings = new MulticlassExperimentSettings\r\n{\r\n    MaxExperimentTimeInSeconds = (uint)(trainer.TrainingDuration * 60),\r\n    CacheDirectory = new DirectoryInfo(ModelCache),\r\n    OptimizingMetric = MulticlassClassificationMetric.MicroAccuracy\r\n};\r\n\r\nvar experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(settings);\r\nvar progress = new Progress<RunDetail<MulticlassClassificationMetrics>>(p =>{});\r\nvar result = experiment.Execute(trainSet, testSet, labelColumnName: \"Classification\", progressHandler: progress);\r\n\r\n\r\n![vs](https://user-images.githubusercontent.com/31455766/81232882-eceb0f80-8fb2-11ea-9686-acba9c57b898.jpg)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5101","RelatedDescription":"Open issue \"Negative scores evalauate for LightGBMMulti model\" (#5101)"},{"Id":"613625073","IsPullRequest":true,"CreatedAt":"2020-05-06T21:29:11","Actor":"frank-dong-ms","Number":"5099","RawContent":null,"Title":"disable test that are hanging and failing","State":"open","Body":"Due to some recent CI failing, disable some test to unblock:\r\n\r\nHanging: \r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=632387&view=logs&j=fbb2cc91-8ee3-5485-dfe8-a5681da76491&t=12433ff8-7284-5589-30ac-02bd5974b6ad\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=631965&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1&t=4390109a-3c77-5b7c-bf35-d176b654cd3c\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=631033&view=logs&j=d1af5113-e574-5a31-f7f3-02fc40ea7b26&t=167d9e7d-b609-5b0a-7efa-d26b0dafb88f\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=630228&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1&s=b15d9194-8f26-5328-b47f-5968c76b37e7\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=628376&view=logs&j=9dffbc46-9322-5a58-fb37-6d66c044e90d&t=11098bf6-eb78-583b-8eab-f14f48444a6b\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=628134&view=logs&j=41509eb4-74ce-5e57-61b4-bdf74b39e7c1&t=dbdc2969-5b98-5c39-1328-31d4a2fdc45e\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=626424&view=logs&j=d1af5113-e574-5a31-f7f3-02fc40ea7b26&t=167d9e7d-b609-5b0a-7efa-d26b0dafb88f\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=620750&view=logs&j=32952595-30e7-56fa-9b86-c4579b87f5d1&s=d654deb9-056d-50a2-1717-90c08683d50a\r\n\r\nFail:\r\n\r\nhttps://dev.azure.com/dnceng/public/_build/results?buildId=614989&view=logs&j=4b233af4-7b14-5f68-27c6-9c4d7ac87519&t=6e2e87e8-8c33-50e6-544b-c271638494a5","Url":"https://github.com/dotnet/machinelearning/pull/5099","RelatedDescription":"Open PR \"disable test that are hanging and failing\" (#5099)"},{"Id":"611812327","IsPullRequest":false,"CreatedAt":"2020-05-06T17:15:29","Actor":"nsulikowski","Number":"5089","RawContent":null,"Title":"The future of ML.NET","State":"closed","Body":"Back in 3/26/2020 I was surveyed by members of the ML.NET team, who were gathering feedback about uses of ML.NET. \r\nI'm wondering broadly what the future of ML.NET will look like? Will you continue to invest in making it a stand alone product for machine learning, extending the breath and depth of the library? Or perhaps it'll end up being more of a hosting environment for models and statistical studies built in other languages like python/R ?\r\nI personally would love to have ML.NET eventually be a one stop shop, with everything I need. But I wonder what the team is thinking? \r\nThanks! ","Url":"https://github.com/dotnet/machinelearning/issues/5089","RelatedDescription":"Closed issue \"The future of ML.NET\" (#5089)"},{"Id":"613253035","IsPullRequest":false,"CreatedAt":"2020-05-06T11:38:21","Actor":"iluveu28","Number":"5096","RawContent":null,"Title":"Add new models in prediction pool during runtime","State":"open","Body":"I have two separate .NET Core Web API projects deployed to Kubernetes as separate Docker containers. One for training and the other for predictions. The users can upload a training file into the training API to create a new model and the filename and path of the model.zip file are saved into a table in SQL Server DB and the model.zip file is saved in PersistentVolume. \r\n\r\nIn the prediction service, I create the PredictionEnginePool in ConfigureServices in Startup.cs. \r\n\r\nHow can I lookup a model by name to check if my models have been loaded into the pool and if not, how can I dynamically add the newly trained models that had just been created by the separate training API without having to restart the prediction API ? Is there any way I can do this outside of the Startup.cs e.g. in the controller so that I can take control of the pool at runtime?\r\n\r\nCan you provide sample codes that dynamically read .zip files from a folder, check if they're already in the pool and if not then add it into the prediction pool, all done inside a controller?","Url":"https://github.com/dotnet/machinelearning/issues/5096","RelatedDescription":"Open issue \"Add new models in prediction pool during runtime\" (#5096)"},{"Id":"612863000","IsPullRequest":true,"CreatedAt":"2020-05-06T07:26:10","Actor":"mstfbl","Number":"5094","RawContent":null,"Title":"Re-enabled BinaryClassifierSymSgdTest with platform-specific baselines","State":"closed","Body":"\r\nThis PR re-enables the unit test `BinaryClassifierSymSgdTest()` on MacOS and Linux by adding MacOS and Linux-specific baselines for the test. The test works properly on these builds as the platform-specific baselines are consistent between each run.","Url":"https://github.com/dotnet/machinelearning/pull/5094","RelatedDescription":"Closed or merged PR \"Re-enabled BinaryClassifierSymSgdTest with platform-specific baselines\" (#5094)"},{"Id":"612672218","IsPullRequest":true,"CreatedAt":"2020-05-05T15:01:17","Actor":"aslotte","Number":"5091","RawContent":null,"Title":"Pass in caught exception to inner exception in LoadTFSession","State":"open","Body":"Fixes #4409 \r\n\r\n## Description\r\nPassing in the caught exception as an inner exception to retain stack trace and information.\r\nI was unable to find a suitable place to add a unit test for this feature. Please feel free to instruct me where I will be able to add that if needed.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5091","RelatedDescription":"Open PR \"Pass in caught exception to inner exception in LoadTFSession\" (#5091)"},{"Id":"611694277","IsPullRequest":true,"CreatedAt":"2020-05-04T08:29:48","Actor":"mstfbl","Number":"5087","RawContent":null,"Title":"Debugging tests disabled on Linux and MacOS builds","State":"open","Body":"Debugging PR for diagnosing tests disabled on Linux and MacOS builds:\r\n\r\nDisabled tests - Disabled build(s):\r\n- `BinaryClassifierSymSgdTest()` - Linux, MacOS\r\n- `TextNormalizingOnnxConversionTest()` - Linux\r\n- `MatrixFactorizationSimpleTrainAndPredict()` - MacOS\r\n\r\nReport:\r\n- `BinaryClassifierSymSgdTest()`\r\n  - Fixed, added new baselines for Linux and MacOS builds with PR #5094 .\r\n- `MatrixFactorizationSimpleTrainAndPredict()`\r\n  - The baseline on MacOS varies greatly. In 10 consecutive tests, the calculated MSE ranged between 0.586040127051849 to 0.625339146273452. With these results, a tolerance of `Math.Pow(10, -1)` is required.\r\n  - I have been able to reproduce this issue on my own MacOS computer.\r\n  - Issue stems from [here](https://github.com/cjlin1/libmf/blob/e70b9a32f7df32cce961bbbb997da074759a16fe/mf.cpp#L1121).  This random_shuffle libmf function shuffle values with a rand(). With no given seed, it behaved non-deterministically. By commenting out this shuffling, the MSEs on MacOS and Windows are now very close, within 2 decimal digits, and these are consistent.\r\n- `TextNormalizingOnnxConversionTest()`\r\n  - Will be fixed when Issue #5093 is fixed.\r\n  - This test fails on the Linux Net CoreApp 2.1 builds on Linux with the following error:\r\n\r\n  - > System.InvalidOperationException : Error initializing model :Microsoft.ML.OnnxRuntime.OnnxRuntimeException: [ErrorCode:RuntimeException] Exception during initialization: /onnxruntime_src/onnxruntime/core/providers/cpu/nn/string_normalizer.cc:87 onnxruntime::string_normalizer::Locale::Locale(const string&) Failed to construct locale with name:en_US.UTF-8:locale::facet::_S_create_c_locale name not valid:Please, install necessary language-pack-XX and configure locales\r\n\r\n  - The issue being faced here may be different than before, as the error being faced is related to locales. As this test passes on MacOS Net Core App 2.1 and Linux Net Core App 3.1, this may be a Linux Net Core App 2.1 or more specifically Ubuntu Net Core App 2.1 issue.\r\n\r\n  - The ONNX team faced the exact same issue as this, and they have fixed it with [this PR](https://github.com/onnx/backend-scoreboard/pull/19), which installs the appropiate locales in their docker instance.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5087","RelatedDescription":"Open PR \"Debugging tests disabled on Linux and MacOS builds\" (#5087)"},{"Id":"611555591","IsPullRequest":false,"CreatedAt":"2020-05-04T01:24:10","Actor":"luisquintanilla","Number":"5086","RawContent":null,"Title":"Auto.ML.0.16.0 and System.Memory 4.0.1.0","State":"open","Body":"Moving issue raised by @ericdransfeldt in Docs repo since it's a product question.\r\n\r\nHi,\r\n\r\nI love the Microsoft.ML and AutoML platforms but am having an issue when I upgraded my AutoML version via NuGet. When I upgraded from Microsoft.ML.AutoML from version 0.15.0 to 0.16.0 I started getting an error when I ran my code. Nothing changed in my source code except to recompile. It seems like it can't find System.Memory 4.0.1.0.\r\n\r\nCould not load file or assembly 'System.Memory, Version=4.0.1.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51' or one of its dependencies. The system cannot find the file specified., Stack: at Microsoft.ML.Data.InternalSchemaDefinition.GetVectorAndItemType(String name, Type rawType, IEnumerable1 attributes, Boolean& isVector, Type& itemType) at Microsoft.ML.Data.InternalSchemaDefinition.GetVectorAndItemType(MemberInfo memberInfo, Boolean& isVector, Type& itemType) at Microsoft.ML.Data.SchemaDefinition.Create(Type userType, Direction direction) at Microsoft.ML.Data.DataViewConstructionUtils.CreateFromEnumerable[TRow](IHostEnvironment env, IEnumerable1 data, SchemaDefinition schemaDefinition)\r\n\r\nI went back to the older version and it worked fine. No dependency issues.. Any ideas..?\r\n\r\nThanks for any help or ideas!\r\n\r\nCheers,\r\nEric","Url":"https://github.com/dotnet/machinelearning/issues/5086","RelatedDescription":"Open issue \"Auto.ML.0.16.0 and System.Memory 4.0.1.0\" (#5086)"},{"Id":"611465827","IsPullRequest":true,"CreatedAt":"2020-05-03T17:37:55","Actor":"jwood803","Number":"5085","RawContent":null,"Title":"Update OnnxTransformer Doc XML","State":"open","Body":"Update for #4707.\r\n\r\nUpdates the doc XML to use the latest dynamic API.","Url":"https://github.com/dotnet/machinelearning/pull/5085","RelatedDescription":"Open PR \"Update OnnxTransformer Doc XML\" (#5085)"},{"Id":"611269075","IsPullRequest":true,"CreatedAt":"2020-05-03T06:20:34","Actor":"mstfbl","Number":"5084","RawContent":null,"Title":"Added SciSharp.TensorFlow as a dependency to Microsoft.ML.TensorFlow","State":"closed","Body":"Fix #4065. Added package reference to `SciSharp.TensorFlow.Redist` in `Microsoft.ML.TensorFlow`, and removed this package reference from `Microsoft.ML.Tests`, as `Microsoft.ML.Tests` already has a reference to `Microsoft.ML.TensorFlow.`\r\n\r\n`Microsoft.ML.Tensorflow.csproj` did not include a package reference to `SciSharp.TensorFlow.Redist`, which resulted in users needing to manually install this NuGet package, as demonstrated in issue #4065. I confirmed that this fix works [here](https://github.com/dotnet/machinelearning/issues/4065#issuecomment-623009939).","Url":"https://github.com/dotnet/machinelearning/pull/5084","RelatedDescription":"Closed or merged PR \"Added SciSharp.TensorFlow as a dependency to Microsoft.ML.TensorFlow\" (#5084)"},{"Id":"611227166","IsPullRequest":false,"CreatedAt":"2020-05-02T16:37:29","Actor":"ddobric","Number":"5083","RawContent":null,"Title":"Docker issue with TensorFlow inception_v3.meta model","State":"open","Body":"### System information\r\n\r\n- Windows 10, Docker desktop Linux. v. 19.03.8, build afacb8b\r\n- .NET Core Version 3.1\r\n- ML.NET 1.4.0\r\n\r\n### Issue\r\nWhen working with image classification and TensorFlow model, the TensorFlowUtils tries to download the inception file.\r\nFirst of all the dockerfile already copies the inception file to the /tmp/MLNET location. As you can see on the picture the file is in there. It is trying to download it if the file already exists?\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/80869999-ed7a6200-8ca3-11ea-8904-0b49822331e1.png)\r\n\r\nHow to prevent downloading of the inception file?\r\n\r\nThanks\r\nDamir","Url":"https://github.com/dotnet/machinelearning/issues/5083","RelatedDescription":"Open issue \"Docker issue with TensorFlow inception_v3.meta model\" (#5083)"}],"ResultType":"GitHubIssue"}},"RunOn":"2020-05-11T05:30:38.1371124Z","RunDurationInMilliseconds":624}